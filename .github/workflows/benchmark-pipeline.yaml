name: Benchmark Pipeline

on:
  workflow_dispatch:
    inputs:
      cncf_project:
        description: Project to be deployed e.g. falco
        required: true
        type: choice
        options:
          - falco
      config:
        description: Configuration if project has multiple variants they wish to test (defaults to all)
        required: false
        type: string
      version:
        description: Version of project to be tested e.g. 0.37.0
        required: true
        type: string
      benchmark_job_url:
        description: URL of the benchmark job
        required: true
        type: string
      benchmark_job_duration_mins:
        description: Duration of the benchmark job
        required: true
        type: number

concurrency:
  group: benchmark

jobs:
  print_summary:
    runs-on: ubuntu-latest
    steps:
      - name: Add to Summary
        run: |
          echo "## Workflow Input Parameters" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "| --- | --- |" >> $GITHUB_STEP_SUMMARY
          echo "| cncf_project | ${{ github.event.inputs.cncf_project }} |" >> $GITHUB_STEP_SUMMARY
          echo "| config | ${{ github.event.inputs.config }} |" >> $GITHUB_STEP_SUMMARY
          echo "| version | ${{ github.event.inputs.version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| benchmark_job_url | ${{ github.event.inputs.benchmark_job_url }} |" >> $GITHUB_STEP_SUMMARY
          echo "| benchmark_job_duration_mins | ${{ github.event.inputs.benchmark_job_duration_mins }} |" >> $GITHUB_STEP_SUMMARY


  deploy:
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
      - uses: azure/setup-kubectl@v4
        with:
          version: v1.30.2
        id: install
      - run: mkdir ~/.kube && echo "${{ secrets.KUBECONFIG }}" > ~/.kube/config
      - name: Select the manifest
        run: |
          MANIFEST=projects/${{ inputs.cncf_project }}
          CONFIG=${{ inputs.config }}
          if [[ -n $CONFIG ]]; then
            echo "Configuration provided"
            MANIFEST=$MANIFEST/$CONFIG.yaml
          else
            MANIFEST=$MANIFEST/${{ inputs.cncf_project }}.yaml
          fi

          if ! test -f "$MANIFEST"; then
            echo "The provided inputs are invalid."
            exit 1
          fi

          export VERSION=${{ inputs.version }}
          envsubst < $MANIFEST > manifest.yaml
      - uses: actions/upload-artifact@v4
        with:
          name: manifest
          path: manifest.yaml
      - name: Apply the manifest
        run: |
          kubectl apply -f manifest.yaml

          sleep 10

          kubectl wait pod \
          --all \
          --for=condition=Ready \
          --namespace=falco # TODO: Revert to "benchmark" this after merging https://github.com/falcosecurity/cncf-green-review-testing/pull/22

  benchmark-job:
    runs-on: ubuntu-24.04
    needs: deploy
    steps:
      - uses: actions/checkout@v4
      - uses: azure/setup-kubectl@v4
        with:
          version: v1.30.2
        id: install
      - run: mkdir ~/.kube && echo "${{ secrets.KUBECONFIG }}" > ~/.kube/config
      - name: Run the benchmark job
        run: |
          kubectl apply -f ${{ inputs.benchmark_job_url }}

          kubectl wait pod \
          --all \
          --for=condition=Ready

      - name: Wait for the benchmark job to complete
        run: |
          sleep ${{ inputs.benchmark_job_duration_mins }}m

      - name: Delete the benchmark job
        run: |
          kubectl delete -f ${{ inputs.benchmark_job_url }} --wait

  delete:
    runs-on: ubuntu-24.04
    needs: benchmark-job
    if: ${{ always() }}
    steps:
      - uses: actions/checkout@v4
      - uses: azure/setup-kubectl@v4
        with:
          version: v1.30.2
        id: install
      - run: mkdir ~/.kube && echo "${{ secrets.KUBECONFIG }}" > ~/.kube/config

      - uses: actions/download-artifact@v4
        with:
          name: manifest
      - run: kubectl delete -f manifest.yaml --wait
